{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Daniel Alvarez\n",
    "\n",
    "<alvarez.da@gmail.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.3.3-py3-none-macosx_10_14_x86_64.macosx_10_15_x86_64.macosx_11_0_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /anaconda/anaconda3/lib/python3.6/site-packages (from xgboost) (1.17.4)\n",
      "Requirement already satisfied: scipy in /anaconda/anaconda3/lib/python3.6/site-packages (from xgboost) (1.3.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /anaconda/anaconda3/lib/python3.6/site-packages (3.1.1)\r\n",
      "Requirement already satisfied: scipy in /anaconda/anaconda3/lib/python3.6/site-packages (from lightgbm) (1.3.2)\r\n",
      "Requirement already satisfied: numpy in /anaconda/anaconda3/lib/python3.6/site-packages (from lightgbm) (1.17.4)\r\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /anaconda/anaconda3/lib/python3.6/site-packages (from lightgbm) (0.23.1)\r\n",
      "Requirement already satisfied: wheel in /anaconda/anaconda3/lib/python3.6/site-packages (from lightgbm) (0.34.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/anaconda3/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /anaconda/anaconda3/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.14.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boruta\n",
      "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 1.8 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /anaconda/anaconda3/lib/python3.6/site-packages (from boruta) (1.17.4)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /anaconda/anaconda3/lib/python3.6/site-packages (from boruta) (0.23.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /anaconda/anaconda3/lib/python3.6/site-packages (from boruta) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/anaconda3/lib/python3.6/site-packages (from scikit-learn>=0.17.1->boruta) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /anaconda/anaconda3/lib/python3.6/site-packages (from scikit-learn>=0.17.1->boruta) (0.14.1)\n",
      "Installing collected packages: boruta\n",
      "Successfully installed boruta-0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import packages.\n",
    "\n",
    "# General libraries.\n",
    "import os, platform, sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "#from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "#Standardize variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import joblib for data persistance\n",
    "import joblib\n",
    "\n",
    "# import parquet for persistence\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# SK-learn libraries for learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet, Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GB\n",
    "from sklearn.ensemble import ExtraTreesRegressor as ET\n",
    "from sklearn.ensemble import AdaBoostRegressor as AB\n",
    "\n",
    "#import lightgbm\n",
    "#from lightgbm import LGBMClassifier\n",
    "#import xgboost as xgb\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "#from sklearn.impute import IterativeImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, average_precision_score, confusion_matrix, plot_confusion_matrix, classification_report, roc_curve, auc, f1_score, make_scorer, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# apply Boruta method for dimensionality reduction\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# Set display of images in the notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posix\n",
      "Platform system: Darwin. Release version: 18.6.0\n",
      "3.6.10 |Anaconda, Inc.| (default, Mar 23 2020, 17:45:12) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Numpy version: 1.14.2\n",
      "Pandas version: 0.25.3\n",
      "Seaborn version: 0.10.0\n",
      "Joblib version: 0.14.1\n"
     ]
    }
   ],
   "source": [
    "# check versions\n",
    "print(os.name)\n",
    "print(f'Platform system: {platform.system()}. Release version: {platform.release()}')\n",
    "print(sys.version)\n",
    "\n",
    "print(f'Numpy version: {np.__version__}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'Seaborn version: {sns.__version__}')\n",
    "print(f'Joblib version: {joblib.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set random seed for this project\n",
    "random_seed = 224\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data from csv and set data types (dtype), except the first column -'calldate'- which will be parsed later.\n",
    "df = pd.read_csv(\"  .csv\", sep=',', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert columns to str without spaces in lower case\n",
    "df.columns = df.columns.str.replace('\\s+', '_').str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inspect the dataframe\n",
    "print(df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# last 5 rows\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### analyze null values\n",
    "def nullvalues(d):\n",
    "    ''' Number of null values for each feature and percentage of null values for each feature'''\n",
    "    print(\"{:60s}|{:18s}|{:10s}\".format(\"Feature\",\"Null values\",\"Null Values as a Percent of Total\"))\n",
    "    print(\"=\"*100)\n",
    "    for col in d.columns:\n",
    "        null_values = d[col].isnull().sum(axis=0)\n",
    "        null_values_pct = d[col].isnull().sum(axis=0)/len(d)*100\n",
    "        print(\"{:60s}|{:14d}\\t|{:6f}\".format(str(col),null_values,null_values_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nullvalues(d=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### analyze cardinality\n",
    "def cardinality(data):\n",
    "    ''' Check number of unique values of variables not accounting for null values '''\n",
    "    print(\"{:35s}\\t| {:10s}\\t| {:10s}\".format(\"Feature\",\"Distinct Values\",\"Distinct Values as a Percent of Total\"))\n",
    "    print(\"=\"*100)\n",
    "    for col in data.columns[:]:\n",
    "        unique_values = len(np.unique(data[col].ffill()))\n",
    "        unique_values_pct = len(np.unique(data[col].ffill()))/len(data) \n",
    "        print(\"{:35s}\\t| {:10d}\\t\\t| {:6f}\".format(str(col),unique_values,unique_values_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cardinality(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### analyze duplicates\n",
    "def rowduplication(data):\n",
    "    ''' Assess the number and percent of duplicates for entire rows in dataset '''\n",
    "    data_dedup = data.drop_duplicates(keep='first')\n",
    "    data_duplicates = data[data.duplicated(subset=None, keep='first')]\n",
    "    \n",
    "    print('Shape of de-duplicated dataset', data_dedup.shape)\n",
    "    print('Number of duplicates:', len(data) - len(data_dedup))\n",
    "    print('Confirm number of duplicates:', len(data_duplicates)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowduplication(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def duplicationanalyzer(data):\n",
    "    ''' Assess the number and percentage of duplicates for each variable in the dataset'''\n",
    "    variable = pd.Series(np.nan)\n",
    "    \n",
    "    for var in data:\n",
    "        ''' Output the number of duplicates and percentage of duplicates '''\n",
    "        variable = data[var]\n",
    "        \n",
    "        # construct variable dataframe less duplicates\n",
    "        variable_dedup = variable.drop_duplicates(keep='first')\n",
    "        \n",
    "        #print the number of duplicates\n",
    "        duplicates=data[data[var].duplicated(keep=False)]\n",
    "        print(var)\n",
    "        print('Number of duplicates: ', len(duplicates))\n",
    "        \n",
    "        #print the percentage of duplicates\n",
    "        percentage = \"{0:.2f}\".format(len(duplicates)/len(data))\n",
    "        print('Percentage of duplicates: ', percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "duplicationanalyzer(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define functions for summary statistics on categorical and numeric variables\n",
    "\n",
    "def catvardistribution(data, var, title):\n",
    "    ''' Examine value counts and countplots'''\n",
    "    print(data[var].value_counts(dropna=False))\n",
    "    sns.set(style='darkgrid')\n",
    "    ax = sns.countplot(x=data[var], data=data)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "def summarystats(data, var, titleplot, n_bins):\n",
    "    ''' Print summary statistics, show histogram and boxplot '''\n",
    "    print(data[var].unique())\n",
    "    print(data[var].describe())\n",
    "    n_bins = n_bins\n",
    "    #fig, axs = plt.subplots(1, 1, sharey=True, tight_layout=True)\n",
    "    plt.hist(data[var], bins=n_bins)\n",
    "    plt.title(titleplot, loc='center', pad=None)\n",
    "    plt.show()\n",
    "    sns.set(style='darkgrid')\n",
    "    ax = sns.boxplot(x=data[var])\n",
    "    print(ax)\n",
    "\n",
    "def sidebysideboxplots(data, xvar, yvar, xtitle, ytitle):\n",
    "    ''' Generate side-by-side boxplots'''\n",
    "    ax = sns.boxplot(x=xvar, y=yvar, data=data)\n",
    "    ax.set_xlabel(xtitle)\n",
    "    ax.set_ylabel(ytitle)\n",
    "\n",
    "def corrmap(data,figx, figy):\n",
    "    '''Generate correlation heatmap'''\n",
    "    var_corr = data.corr()\n",
    "    var_corr = var_corr.round(3)\n",
    "    # plot the heatmap and annotation on it\n",
    "    fig, ax = plt.subplots(figsize=(figx,figy))         # Sample figsize\n",
    "    sns.heatmap(var_corr, xticklabels=var_corr.columns, yticklabels=var_corr.columns, annot=True)\n",
    "\n",
    "    # Fix axes\n",
    "    b, t = plt.ylim() # discover the values for bottom and top\n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "    plt.show()\n",
    "    \n",
    "def binary_means(data, feature_group, y_col):\n",
    "    ''' Show mean scores by feature category '''\n",
    "    cols = feature_dict[feature_group]\n",
    "    #cols = feat_eng\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        print(df.groupby(y_col)[col].mean())\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save dictionary of feature lists\n",
    "feature_dict = {'xxx':xxx, 'ids':ids}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save engineered features into a list\n",
    "feat_eng = ['xxx','xxy']\n",
    "feature_dict['feat_eng'] = feat_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_means(df,'feat_eng','label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_absolute_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d0a4b1e19b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Absolute Error: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev0_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mknn_predictions_rounded_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Squared Error: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev0_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mknn_predictions_rounded_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Root Mean Squared Error: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev0_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mknn_predictions_rounded_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_absolute_error' is not defined"
     ]
    }
   ],
   "source": [
    "# check percentage of null values among model features\n",
    "def check_null_percent(data_for_modeling, X_cols):\n",
    "    return((data_for_modeling[X_cols].isnull().sum().sort_values(ascending=False).head(10)/data_for_modeling.shape[0])*100)\n",
    "\n",
    "# Prediction errors\n",
    "def prediction(actual,pred):\n",
    "    ''' Compute prediction errors'''\n",
    "    print(\"Mean Absolute Error: %s\" %mean_absolute_error(actual,pred))\n",
    "    print(\"Mean Squared Error: %s\" %mean_squared_error(actual,pred))\n",
    "    print(\"Root Mean Squared Error: %s\" %sqrt(mean_squared_error(actual,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply randomized search cross-validation for a given classifier\n",
    "def model_pipeline(imputer, scaler, estimator, params, scoring_metric, X_train, y_train, X_test, y_test, multi=False):\n",
    "    pipeline = Pipeline([('imputer', imputer),\n",
    "                         ('scaler', scaler),\n",
    "                         ('estimator', estimator)])\n",
    "    print(pipeline)\n",
    "    search = RandomizedSearchCV(pipeline, param_distributions=params, n_iter=100,\n",
    "                                scoring=scoring_metric, cv=5, refit=True, verbose=1, n_jobs=-1)\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    print('training set')\n",
    "    prediction(actual=y_train, search.predict(X_train))\n",
    "\n",
    "    print('test set')\n",
    "    prediction(actual=y_test, search.predict(X_test))  \n",
    "    \n",
    "    print('best parameters')\n",
    "    print(pd.Series(search.best_params_))\n",
    "    \n",
    "    return(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_importance(search, X_cols, model_type):\n",
    "    ''' Show feature importance '''\n",
    "    feat_importance = pd.DataFrame()\n",
    "    if model_type == 'linear':\n",
    "        feat_importance = pd.DataFrame([search.best_estimator_['estimator'].coef_[0]], columns=X_cols).T\n",
    "        feat_importance.columns = ['coef']\n",
    "        feat_importance['abs_coef'] = np.abs(feat_importance['coef'])\n",
    "        feat_importance.sort_values('abs_coef', ascending=False, inplace=True)\n",
    "    elif model_type == 'tree':\n",
    "        feat_importance = pd.DataFrame([search.best_estimator_['estimator'].feature_importances_], columns=X_cols).T\n",
    "        feat_importance.columns = ['importance']\n",
    "        feat_importance.sort_values('importance', ascending=False, inplace=True)\n",
    "    return(feat_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_col = 'label'\n",
    "data_for_modeling = df[(df[y_col].isnull()==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temporal train and test\n",
    "# df_train = data_for_modeling[data_for_modeling['date']<=datetime.date(yyyy,mm,dd)]\n",
    "# df_dev = data_for_modeling[data_for_modeling['date']>datetime.date(yyyy,mm,dd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random split by dates\n",
    "def ts_daily_train_dev_split(df, date_feature, test_size, random_state=None):\n",
    "    \n",
    "    \"\"\"Time Series Cross Validator, avoids shuffling information within unique days.\n",
    "    \n",
    "    Given a dataframe containing time series with a time step shorter than 1 day and with a variable containing each\n",
    "    unique date (day), returns 2 dataframes with train and test sets, where data belonging to every unique day can be in\n",
    "    one of the test sets only.\n",
    "    \n",
    "    param df: original dataframe\n",
    "    param date feature: datetime feature name to split by\n",
    "    param test_size: test size relative to whole size [0, 1]\n",
    "    param random_state: random state to replicate the split\n",
    "    \n",
    "    return df_train: dataframe with training set\n",
    "    return df_dev: dataframe with development(dev) set\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the list of unique dates in df and create a pandas Series\n",
    "    days_list = df[date_feature].unique()\n",
    "    sampled_series = pd.Series(days_list)\n",
    "    \n",
    "    # Get train and dev dates(days)\n",
    "    train, dev = train_test_split(sampled_series, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Split dataframe\n",
    "    df_train = df.loc[df[date_feature].isin(train)]\n",
    "    df_dev = df.loc[df[date_feature].isin(dev)]\n",
    "    \n",
    "    # Return data sets\n",
    "    return df_train, df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_frac = 0.2\n",
    "ts_daily_train_dev_split(df=data_for_modeling, date_feature='date', test_size=test_frac, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random split general - not by dates\n",
    "#stratify randomization by label and relevant features\n",
    "test_frac = 0.2\n",
    "df_train, df_dev = train_test_split(data_for_modeling, test_size=test_frac, \n",
    "                               random_state=random_seed, stratify=data_for_modeling[[y_col]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the X train and dev datasets\n",
    "X_train = df_train.drop('label', axis=1)\n",
    "X_dev = df_dev.drop('label', axis=1)\n",
    "\n",
    "# create the target variable\n",
    "y_train = df_train[y_col]\n",
    "y_dev = df_dev[y_col]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Boruta methods for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove unwanted features\n",
    "X_cols = list(X_train.columns)\n",
    "for x in ['xxx', 'xxy', 'xxz']:\n",
    "    X_cols.remove(x)\n",
    "\n",
    "for x in X_cols:\n",
    "    if X_train[x].dtypes == 'object':\n",
    "        X_cols.remove(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute missing values and standardize values \n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "imputer.fit(df_train[X_cols])\n",
    "Ximp = imputer.transform(df_train[X_cols])\n",
    "scaler.fit(Ximp)\n",
    "Xscaled = scaler.transform(Ximp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate random forest\n",
    "forest = RandomForestRegressor(n_jobs = -1, max_depth = 5)\n",
    "\n",
    "# fit boruta\n",
    "boruta_selector = BorutaPy(forest, n_estimators = 'auto', random_state = 0)\n",
    "boruta_selector.fit(np.array(Xscaled), np.array(df_train[y_col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select top 20 features following Boruta ranking\n",
    "boruta_ranking = boruta_selector.ranking_\n",
    "for i, val in enumerate(boruta_ranking):\n",
    "    if val <= 20:\n",
    "        print (val, X_cols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_X_cols = X_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store results\n",
    "boruta_ranking = boruta_selector.ranking_\n",
    "selected_features = np.array(X_cols)[boruta_ranking <= 2]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign scoring metric \n",
    "scoring_metric = 'neg_mean_squared_error'\n",
    "# scoring_metric = 'neg_root_mean_squared_error'\n",
    "# scoring_metric = 'r2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def Gridsearch_knn(param_grid, cv, train_data, train_target):\n",
    "#     ''' Fit a KNN regression model and find the optimal value for k '''\n",
    "#     # GridSearchCV method call to extract parameter values from KNN estimator\n",
    "#     reg = GridSearchCV(KNeighborsRegressor(), k_range, cv=cv, iid=False, n_jobs=-1)\n",
    "    \n",
    "#     # Fit on the train set\n",
    "#     reg_fit = reg.fit(train_data, train_target)\n",
    "\n",
    "#     return reg_fit.best_params_['n_neighbors']\n",
    "     \n",
    "# # define the parameter values that should be searched\n",
    "# # Create the k parameter grid to search over in the GridSearchCV method call\n",
    "# # single key-value pair for param_grid\n",
    "# k_range = {'n_neighbors': list(range(1,50,1))}\n",
    "    \n",
    "# # Tune the hyperparameters to find the optimal value for k in the KNN regression\n",
    "# best_k = Gridsearch_knn(param_grid= k_range, cv = 5, train_data = X_train, train_target = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # calculate predicted values on dev data\n",
    "# knn = KNeighborsRegressor(n_neighbors=best_k, weights='distance')\n",
    "# knn.fit(X_train, y_train) \n",
    "# knn_predictions = np.round(knn.predict(X_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # evaluate predictions\n",
    "# prediction(actual=y_dev, pred=knn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN regression\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "scaler = StandardScaler()\n",
    "estimator = KNN(random_state=random_seed)\n",
    "params = {'estimator__n_neighbors': list(range(1,50,1)),\n",
    "          'estimator__weights: ['uniform', 'distance'],\n",
    "          'estimator__algorithm: ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "knn = model_pipeline(imputer, scaler, estimator, params, scoring_metric, \n",
    "                    df_train[selected_features], df_train[y_col], df_dev[selected_features], df_dev[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assess feature importance\n",
    "feat_importance(knn, X_cols=selected_features, 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LASSO regression\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "scaler = StandardScaler()\n",
    "estimator = LinearRegression(random_state=random_seed)\n",
    "params = {'n_features_to_select': list(range(1, len(selected_features)))}\n",
    "\n",
    "lr = model_pipeline(imputer, scaler, estimator, params, scoring_metric, \n",
    "                    df_train[selected_features], df_train[y_col], df_dev[selected_features], df_dev[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assess feature importance\n",
    "feat_importance(lr, X_cols=selected_features, 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def Gridsearch_lasso(param_grid, cv, train_data, train_target):\n",
    "#     ''' Fit a lasso regression model and find the optimal value for alpha '''\n",
    "#     # GridSearchCV method call to extract parameter values from Ridge Regression estimator\n",
    "#     reg = GridSearchCV(Lasso(max_iter=1000, tol=0.001), alpha_range, cv=cv, iid=False, n_jobs=-1)\n",
    "    \n",
    "#     # Fit on the train set\n",
    "#     reg_fit = reg.fit(train_data, train_target)\n",
    "\n",
    "#     return reg_fit.best_params_['alpha']\n",
    "    \n",
    "# # define the parameter values that should be searched\n",
    "# # Create the alpha parameter grid to search over in the GridSearchCV method call\n",
    "# # single key-value pair for param_grid\n",
    "# alpha_range = {'alpha': list(range(1,1000,3))}\n",
    "    \n",
    "# # Tune the hyperparameters to find the optimal value for alpha in the LASSO regression\n",
    "# best_alpha = Gridsearch_lasso(param_grid= alpha_range, cv = 5, train_data = X_train, train_target = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # calculate predicted values on dev data\n",
    "# lassolr = Lasso(alpha=best_alpha, tol=0.001).fit(X_train, y_train)\n",
    "# lassolr_predictions = np.round(lassolr.predict(X_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # evaluate predictions\n",
    "# prediction(actual=y_dev, pred=lassolr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LASSO regression\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "scaler = StandardScaler()\n",
    "estimator = Lasso(random_state=random_seed)\n",
    "params = {'estimator__alpha': list(range(1,1000,3)),\n",
    "          'estimator__selection': ['cyclic', 'random']}\n",
    "\n",
    "lasso = model_pipeline(imputer, scaler, estimator, params, scoring_metric, \n",
    "                    df_train[selected_features], df_train[y_col], df_dev[selected_features], df_dev[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assess feature importance\n",
    "feat_importance(lasso, X_cols=selected_features, 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def Gridsearch_ridge(param_grid, cv,train_data, train_target):\n",
    "#     ''' Fit a Ridge regression model and find the optimal value for alpha '''\n",
    "#     # GridSearchCV method call to extract parameter values from Ridge Regression estimator\n",
    "#     reg = GridSearchCV(Ridge(), alpha_range, cv=cv, iid=False, n_jobs=-1)\n",
    "    \n",
    "#     # Fit on the train set\n",
    "#     reg_fit = reg.fit(train_data, train_target)\n",
    "\n",
    "#     return reg_fit.best_params_['alpha']\n",
    "     \n",
    "# alpha_range = {'alpha': list(range(0,1000,3))}\n",
    "    \n",
    "# # Tune the hyperparameters to find the optimal value for alpha in the Ridge regression\n",
    "# best_alpha = Gridsearch_ridge(param_grid= alpha_range, cv = 5,train_data = X_train, train_target=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate predicted values on dev data\n",
    "# ridgelr = Ridge(alpha=best_alpha).fit(X_train, y_train)\n",
    "# ridgelr_predictions = np.round(ridgelr.predict(X_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "# prediction(actual=y_dev, pred=ridgelr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ridge regression\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "scaler = StandardScaler()\n",
    "estimator = Ridge(random_state=random_seed)\n",
    "params = {'estimator__alpha': list(range(0,1000,3)),\n",
    "          'estimator__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n",
    "\n",
    "ridge = model_pipeline(imputer, scaler, estimator, params, scoring_metric, \n",
    "                    df_train[selected_features], df_train[y_col], df_dev[selected_features], df_dev[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assess feature importance\n",
    "feat_importance(ridge, X_cols=selected_features, 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest regression\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "scaler = StandardScaler()\n",
    "estimator = RF(random_state=random_seed, bootstrap=True)\n",
    "params = {'estimator__max_leaf_nodes': randint(30,120), 'estimator__max_depth': randint(30, 100),\n",
    "          'estimator__max_features': ['auto','sqrt','log2'],\n",
    "           'estimator__min_samples_leaf': randint(15,50), 'estimator__criterion': ['mse','mae'],\n",
    "           'estimator__n_estimators': randint(30,150)}\n",
    "\n",
    "rf = model_pipeline(imputer, scaler, estimator, params, scoring_metric, \n",
    "                         df_train[selected_features], df_train[y_col], df_dev[selected_features], df_dev[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assess feature importance\n",
    "feat_importance(rf, X_cols=selected_features, 'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting regression\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "scaler = StandardScaler()\n",
    "estimator = GB(learning_rate=0.1, random_state=random_seed)\n",
    "params = {'estimator__max_leaf_nodes': randint(30,120), 'estimator__max_depth': randint(30, 100),\n",
    "           'estimator__min_samples_leaf': randint(15,50), 'estimator__criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "           'estimator__n_estimators': randint(30,150), 'estimator__max_features': ['auto','sqrt','log2'],\n",
    "          'estimator__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "         'estimator__loss':['ls', 'lad', 'huber', 'quantile']} # default to subsample =1\n",
    "\n",
    "gb = model_pipeline(imputer, scaler, estimator, params, scoring_metric, \n",
    "                     df_train[selected_features], df_train[y_col], df_dev[selected_features], df_dev[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assess feature importance\n",
    "feat_importance(gb, X_cols=selected_features, 'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra Trees regression\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "scaler = StandardScaler()\n",
    "estimator = ET(random_state=random_seed)\n",
    "params = {'estimator__max_leaf_nodes': randint(30,120), 'estimator__max_depth': randint(30, 100),\n",
    "           'estimator__min_samples_leaf': randint(15,50), 'estimator__criterion': ['mse', 'mae'],\n",
    "           'estimator__n_estimators': randint(30,150), 'estimator__max_features': ['auto','sqrt','log2']} \n",
    "\n",
    "et = model_pipeline(imputer, scaler, estimator, params, scoring_metric, \n",
    "                     df_train[selected_features], df_train[y_col], df_dev[selected_features], df_dev[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assess feature importance\n",
    "feat_importance(et, X_cols=selected_features, 'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ada Boost regression\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "scaler = StandardScaler()\n",
    "estimator = AB(random_state=random_seed)\n",
    "params = {'estimator__n_estimators': randint(30,150),\n",
    "           'estimator__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "           'estimator__loss':['linear', 'square', 'exponential']} \n",
    "\n",
    "ab = model_pipeline(imputer, scaler, estimator, params, scoring_metric, \n",
    "                     df_train[selected_features], df_train[y_col], df_dev[selected_features], df_dev[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assess feature importance\n",
    "feat_importance(ab, X_cols=selected_features, 'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLPClassifier\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "scaler = StandardScaler()\n",
    "classifier = MLPClassifier(random_state=random_seed)\n",
    "params = {'classifier__hidden_layer_sizes': randint(3, 100), \n",
    "          'classifier__activation': ['identity','logistic','tanh','relu'],\n",
    "          'classifier__alpha': [1e4,1e3,1e2], \n",
    "          'classifier__learning_rate': ['constant', 'invscaling','adaptive'], \n",
    "          'classifier__max_iter': randint(150,250), \n",
    "          'classifier__early_stopping': [True, False]}\n",
    "#scoring_metric = 'roc_auc'\n",
    "mlp = model_pipeline(imputer, scaler, classifier, params, scoring_metric, \n",
    "                    df_train[selected_features], df_train[y_col], df_dev[selected_features], df_dev[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(mlp, df_dev[selected_features], df_dev[y_col],\n",
    "                                 display_labels=[\"Categrory 1\", \"Categrory 2\"],\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    \n",
    "    disp.ax_.set_title(title)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:gl-env]",
   "language": "python",
   "name": "conda-env-gl-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
